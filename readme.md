High-Throughput Sparsity-Aware 2-Way SIMD Neural Engine

üìñ Introduction

This project presents a high-performance Fully Connected (FC) Layer Hardware Accelerator optimized for Edge AI inference.

Implemented in Verilog HDL, the design features a novel architecture that combines 2-Way SIMD (Single Instruction, Multiple Data) parallelism with a Dynamic Sparsity-Aware FSM. By detecting and skipping zero-valued inputs at runtime (Zero-Skipping), the engine significantly reduces computation cycles and energy consumption when processing sparse neural network data (e.g., post-ReLU activations).

This project was developed as the Final Project for the Fall 2025 VLSI Design course.

‚ú® Key Features

2-Way SIMD Parallelism: Utilizes a Weight-Stationary architecture to process two neurons per clock cycle, effectively doubling the theoretical throughput.

Dynamic Sparsity Awareness: Implements a "Zero-Skipping" mechanism. When zero inputs are detected, the FSM triggers a "Fast Path" (bypassing multiplication and accumulation), reducing latency by approximately 40% for sparse datasets.

Industrial Quantization Scheme:

Input/Weights: 8-bit Signed Integer (INT8).

Accumulator: 24-bit Signed Integer (INT24) to prevent overflow.

Activation: Hardware-based ReLU with Saturation logic.

Robust Interface: Features a decoupled Request/Acknowledge (input_req / out_valid) handshake protocol for seamless integration with memory subsystems.

üìÇ File Structure

File Name

Type

Description

fc_layer_final.v

Verilog

Core RTL Design. Contains the SIMD datapath, Sparsity-Aware FSM, and ALU logic.

tb_fc_layer.v

Verilog

Testbench. Reads Hex files, drives the DUT, and performs bit-accurate verification against the Golden Model.

model_gen.py

Python

Golden Model Script. Generates synthetic test vectors with controlled sparsity (injected zeros) and calculates expected outputs.

*.hex

Data

Simulation data generated by the Python script:



- inputs.hex, weights.hex, biases.hex, golden_outputs.hex

VLSI .pdf

Report

Final Project Report. Includes detailed architecture diagrams, timing analysis, and waveform interpretation.

üöÄ Quick Start

1. Prerequisites

Ensure you have the following tools installed:

Python 3 (for data generation)

Icarus Verilog (or other simulators like Vivado/ModelSim)

GTKWave (for waveform viewing)

2. Generate Test Data

Run the Python script to generate fresh test vectors (including sparse zero-injections to test the skipping logic):

python3 model_gen.py


This will update the .hex files in your directory.

3. Run Simulation

Compile and run the design using Icarus Verilog:

# Compile RTL and Testbench
iverilog -o sim_output fc_layer_final.v tb_fc_layer.v

# Execute Simulation
vvp sim_output


4. Verify Results

Check the console output for verification status:

Starting Simulation for 5 Test Cases
-----------------------------------------
TEST PASSED! All outputs match Golden Model.
-----------------------------------------


To visualize the Zero-Skipping behavior (Fast Path vs. Full Path):

gtkwave wave.vcd


üìä Performance & Logic

According to the analysis in VLSI .pdf:

Fast Path (Zero Input): 3 Clock Cycles (Logic bypasses Multiply/Accumulate stages).

Full Path (Non-Zero Input): 5 Clock Cycles.

Result: The design achieves variable latency processing, significantly improving efficiency on sparse workloads typical of CNNs/DNNs.

‚öôÔ∏è Configuration

The module is parameterized for scalability (fc_layer_final.v):

parameter DATA_WIDTH  = 8;   // Input/Output width
parameter ACC_WIDTH   = 24;  // Internal Accumulator width
parameter NUM_NEURONS = 10;  // Number of Neurons
parameter NUM_INPUTS  = 4;   // Input Feature Dimension


üìù Author

Author: Yiwei Li

NetID: yl2190

License: MIT